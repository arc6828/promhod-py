{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for Text 1:\n",
      "{\n",
      "    \"language\": \"th\",\n",
      "    \"entities\": [\n",
      "        {\n",
      "            \"type\": \"LOCATION\",\n",
      "            \"value\": \"ในกรุงเทพมหานคร\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"DATE\",\n",
      "            \"value\": \"18 ธันวาคม 2567\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"TIME\",\n",
      "            \"value\": \"09.00 น.\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"ORGANIZATION\",\n",
      "            \"value\": \"ศูนย์ช่วยเหลือสังคม\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"PHONE\",\n",
      "            \"value\": \"1300\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"LOCATION\",\n",
      "            \"value\": \"เทพมหานคร\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"MONEY\",\n",
      "            \"value\": \"3,000 บาท600,000 บาท\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"PERSON\",\n",
      "            \"value\": \"โดยนายอนุรักษ์ มะลิวัลย์\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"LOCATION\",\n",
      "            \"value\": \"ห้องประชุมสหวิชาชีพ  ศูนย์ช่วยเหลือสังคม  ชั้น 1อาคารกรมพัฒนาสังคมและสวัสดิการ\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from langdetect import detect, DetectorFactory\n",
    "from pythainlp.wangchanberta import ThaiNameTagger\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "# Set seed for consistent language detection\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Initialize Thai NER model\n",
    "thai_ner = ThaiNameTagger()\n",
    "\n",
    "# Initialize spaCy English NER model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define mapping for common entity types\n",
    "COMMON_ENTITY_TYPES = {\n",
    "    # spaCy mappings\n",
    "    \"PERSON\": \"PERSON\",\n",
    "    \"NORP\": \"GROUP\",\n",
    "    \"FAC\": \"FACILITY\",\n",
    "    \"ORG\": \"ORGANIZATION\",\n",
    "    \"GPE\": \"LOCATION\",\n",
    "    \"LOC\": \"LOCATION\",\n",
    "    \"PRODUCT\": \"PRODUCT\",\n",
    "    \"EVENT\": \"EVENT\",\n",
    "    \"WORK_OF_ART\": \"WORK_OF_ART\",\n",
    "    \"LAW\": \"LAW\",\n",
    "    \"LANGUAGE\": \"LANGUAGE\",\n",
    "    \"DATE\": \"DATE\",\n",
    "    \"TIME\": \"TIME\",\n",
    "    \"PERCENT\": \"PERCENT\",\n",
    "    \"MONEY\": \"MONEY\",\n",
    "    \"QUANTITY\": \"QUANTITY\",\n",
    "    \"ORDINAL\": \"ORDINAL\",\n",
    "    \"CARDINAL\": \"CARDINAL\",\n",
    "\n",
    "    # WangchanBERTa mappings\n",
    "    \"DATE\": \"DATE\",\n",
    "    \"TIME\": \"TIME\",\n",
    "    \"EMAIL\": \"EMAIL\",\n",
    "    \"LEN\": \"LENGTH\",\n",
    "    \"LOCATION\": \"LOCATION\",\n",
    "    \"ORGANIZATION\": \"ORGANIZATION\",\n",
    "    \"PERSON\": \"PERSON\",\n",
    "    \"PHONE\": \"PHONE\",\n",
    "    \"URL\": \"URL\",\n",
    "    \"ZIP\": \"ZIP\",\n",
    "    \"Money\": \"MONEY\",\n",
    "    \"LAW\": \"LAW\"\n",
    "}\n",
    "\n",
    "def map_entity_type(entity_type, model):\n",
    "    \"\"\"\n",
    "    Map the entity type to a common entity type system.\n",
    "\n",
    "    Args:\n",
    "        entity_type (str): The original entity type from the model.\n",
    "        model (str): The name of the model ('spacy' or 'wangchanberta').\n",
    "\n",
    "    Returns:\n",
    "        str: The mapped entity type.\n",
    "    \"\"\"\n",
    "    return COMMON_ENTITY_TYPES.get(entity_type, \"UNKNOWN\")\n",
    "\n",
    "def unify_entities(entities, model):\n",
    "    \"\"\"\n",
    "    Convert entity types to the common type system.\n",
    "\n",
    "    Args:\n",
    "        entities (list): List of entities with 'type' and 'value'.\n",
    "        model (str): The name of the model ('spacy' or 'wangchanberta').\n",
    "\n",
    "    Returns:\n",
    "        list: Entities with mapped types.\n",
    "    \"\"\"\n",
    "    return [{\"type\": map_entity_type(entity[\"type\"], model), \"value\": entity[\"value\"]} for entity in entities]\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"\n",
    "    Detect the language of the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        str: Detected language code (e.g., 'th' for Thai, 'en' for English).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "def get_named_entities_thai(text):\n",
    "    \"\"\"\n",
    "    Perform NER on Thai text and group nearby entities of the same type.\n",
    "\n",
    "    Args:\n",
    "        text (str): The Thai input text.\n",
    "\n",
    "    Returns:\n",
    "        list: Grouped named entities with spaces for DATE and PERSON types.\n",
    "    \"\"\"\n",
    "    results = thai_ner.get_ner(text)\n",
    "    grouped_entities = []\n",
    "    current_group = {\"type\": None, \"value\": \"\"}\n",
    "\n",
    "    for token, tag in results:\n",
    "        if tag == \"O\":  # Ignore tokens outside any named entity\n",
    "            continue\n",
    "\n",
    "        entity_type = tag.split('-')[-1]  # Extract type (e.g., DATE, PERSON)\n",
    "        \n",
    "        if current_group[\"type\"] == entity_type:\n",
    "            # Add space before the token for DATE and PERSON\n",
    "            if entity_type in [\"DATE\", \"PERSON\"]:\n",
    "                current_group[\"value\"] += \" \" + token\n",
    "            else:\n",
    "                current_group[\"value\"] += token\n",
    "        else:\n",
    "            if current_group[\"type\"]:\n",
    "                # Save the previous group if it exists\n",
    "                grouped_entities.append(current_group)\n",
    "            # Start a new group\n",
    "            current_group = {\"type\": entity_type, \"value\": token}\n",
    "\n",
    "    # Add the last group if it exists\n",
    "    if current_group[\"type\"]:\n",
    "        grouped_entities.append(current_group)\n",
    "\n",
    "    return [{\"type\": entity[\"type\"], \"value\": entity[\"value\"].strip()} for entity in grouped_entities]\n",
    "\n",
    "def get_named_entities_english(text):\n",
    "    \"\"\"\n",
    "    Perform NER on English text using spaCy.\n",
    "\n",
    "    Args:\n",
    "        text (str): The English input text.\n",
    "\n",
    "    Returns:\n",
    "        list: Named entities with their types and values.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [{\"type\": ent.label_, \"value\": ent.text} for ent in doc.ents]\n",
    "\n",
    "def perform_ner_based_on_language(text):\n",
    "    \"\"\"\n",
    "    Perform language detection and NER based on detected language.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the language and grouped named entities.\n",
    "    \"\"\"\n",
    "    language = detect_language(text)\n",
    "    if language == \"th\":\n",
    "        entities = get_named_entities_thai(text)\n",
    "        unified_entities = unify_entities(entities, \"wangchanberta\")\n",
    "    elif language == \"en\":\n",
    "        entities = get_named_entities_english(text)\n",
    "        unified_entities = unify_entities(entities, \"spacy\")\n",
    "    else:\n",
    "        unified_entities = []\n",
    "\n",
    "    return {\"language\": language, \"entities\": unified_entities}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input texts\n",
    "    text1 = \"การประชุมคณะกรรมการพิจารณาให้ความช่วยเหลือผู้ประสบปัญหาทางสังคมในกรุงเทพมหานคร ครั้งที่ 10/2567 วันพุธที่ 18 ธันวาคม 2567 เวลา 09.00 น. ศูนย์ช่วยเหลือสังคม สายด่วน 1300 ดำเนินการจัดประชุมคณะกรรมการพิจารณาให้ความช่วยเหลือผู้ประสบปัญหาทางสังคมในกรุงเทพมหานคร ครั้งที่ 10/2567 เพื่อพิจารณาให้ความช่วยเหลือผู้ประสบปัญหาทางสังคมจำนวน 200 ราย รายละ 3,000 บาท รวมเป็นเงินทั้งสิ้น 600,000 บาท โดยนายอนุรักษ์ มะลิวัลย์ ผู้อำนวยการกองตรวจราชการ เป็นประธาน ณ ห้องประชุมสหวิชาชีพ ศูนย์ช่วยเหลือสังคม ชั้น 1 อาคารกรมพัฒนาสังคมและสวัสดิการ\"\n",
    "    text2 = \"The 10th Meeting of the Committee for Social Assistance in Bangkok for the Year 2567 will be held on Wednesday, December 18, 2024, at 9:00 AM. The Social Assistance Center, Hotline 1300, will organize this meeting to consider providing assistance to 200 individuals facing social problems, with each receiving 3,000 THB, totaling 600,000 THB. The meeting will be chaired by Mr. Anurak Maliwan, Director of the Inspection Division, at the Multidisciplinary Meeting Room, Social Assistance Center, 1st Floor, Department of Social Development and Welfare Building.\"\n",
    "\n",
    "    # Perform NER\n",
    "    result1 = perform_ner_based_on_language(text1)\n",
    "    # result2 = perform_ner_based_on_language(text2)\n",
    "\n",
    "    # Print results as JSON\n",
    "    print(\"Result for Text 1:\")\n",
    "    print(json.dumps(result1, ensure_ascii=False, indent=4))\n",
    "\n",
    "    # print(\"\\nResult for Text 2:\")\n",
    "    # print(json.dumps(result2, ensure_ascii=False, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promhod-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
